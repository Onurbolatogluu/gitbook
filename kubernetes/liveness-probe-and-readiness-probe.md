# ğŸ›  Liveness Probe & Readiness Probe

### Liveness Probe

BazÄ± durumlarda, container iÃ§erisinde baÅŸlatÄ±lan uygulama process Ã§alÄ±ÅŸÄ±yor olsa da, aslÄ±nda yapmasÄ± gereken iÅŸi yapmÄ±yor olabilir.&#x20;

Ã–rneÄŸin, bir web sayfasÄ± yayÄ±nlayan podumuz var. Ä°Ã§erisinde httpd tabanlÄ± bir container Ã§alÄ±ÅŸÄ±yor. Bu pod baÅŸlayÄ±nca, container iÃ§inde ki, httpd deamon ayaÄŸa kalkÄ±yor ve web sitemizi sunmaya baÅŸlÄ±yor. Fakat bir zaman sonra bu servis takÄ±lmaya baÅŸlÄ±yor. Bir hatadan dolayÄ± sayfalarÄ± sunmaya devam edemiyor. Ama httpd uygulamasÄ±, yani servis ayakta. Servis kapanmadÄ± yada Ã§Ã¶kmedi. Ama esas yapmasÄ± gereken iÅŸ olan, web sitemizi sunma iÅŸini yapmÄ±yor.

Bu ve benzeri durumlarÄ± yaÅŸadÄ±ÄŸÄ±mÄ±z zaman ortamda ÅŸÃ¶yle bir sÄ±kÄ±ntÄ± oluÅŸuyor. EÄŸer uygulama Ã§alÄ±ÅŸmÄ±yor olsa, yani uygulama kapansa, kubelet bunu tespit ederek, containerÄ± yeniden baÅŸlatarak sorunu Ã§Ã¶zÃ¼yor.

Fakat uygulama ayakta olmasÄ±na raÄŸmen, yapmasÄ± gereken iÅŸi yapmÄ±yorsa, kubelet bunu, tespit edemiyor. DolayÄ±sÄ±yla containerÄ± yeniden baÅŸlatarak, sorunu Ã§Ã¶zme mekanizmasÄ± Ã§alÄ±ÅŸmÄ±yor. Bu problemi Liveness proble ile Ã§Ã¶zebiliriz.

* Kubelet bir containerÄ±n, ne zaman yeniden baÅŸlatÄ±lacaÄŸÄ±nÄ± bilmek iÃ§in, Liveness probe kullanÄ±r.

Ã–rneÄŸin, Liveness Probe bir uygulamanÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± ancak ilerleme saÄŸlayamadÄ±ÄŸÄ±, bir kitlenmeyi yakalayabilir. BÃ¶yle bir durumda bir containerÄ± yeniden baÅŸlatmak, hatalara raÄŸmen uygulamayÄ±, daha kullanÄ±labilir hale getirmeye yardÄ±mcÄ± olabilir.

Liveness probe ile biz container iÃ§erisinde, bir komut Ã§alÄ±ÅŸtÄ±rarak, ya da http endpointe istek gÃ¶ndererek ya da bir porta tcp connection aÃ§arak uygulamanÄ±n doÄŸru Ã§alÄ±ÅŸÄ±p, Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol etme imkanÄ±na sahip oluyoruz.&#x20;

Bu sorgulamalarÄ±n sonucunda, beklediÄŸimiz sonucu alÄ±rsak, containerÄ±n saÄŸlÄ±klÄ± olduÄŸunu, EÄŸer cevap beklediÄŸimiz gibi deÄŸilse containerÄ±n problemli olduÄŸunu tespit edebiliyoruz. Kubelet bu sorgu sonucuna gÃ¶re aksiyon alabiliyor. Liveness probe tanÄ±mlamalarÄ± yaml iÃ§erisinde LivenessProbe:  parametresi altÄ±nda tanÄ±mlanÄ±yor.

KullanabileceÄŸimiz 3 Tip Probe mevcut;

1 - httpGet

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/liveness
    args:
    - /server
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 3
      periodSeconds: 3
```

Bu probe seÃ§tiÄŸimizde, ÅŸunu diyoruz. Localhost 'a "path" parametresi altÄ±nda belirlediÄŸimiz path'e, "Port" Parametresinde belirlediÄŸimiz porta httpGet isteÄŸi gÃ¶nder. Cevap olarak,  200-400 arasÄ±nda bir cevap kodu dÃ¶nerse, yani cevap alabilirse iÅŸler yolundadÄ±r. Aksi bir cevap dÃ¶nerse, hata olduÄŸunu anlayÄ±p, containerÄ± restart et. Ä°steÄŸimize custom bir http headerÄ± ekleyebiliriz.

InÄ±tÄ±alDelaySeconds ve PeriodSeconds parametreleri, ÅŸu iÅŸe yarÄ±yor; Bir pod oluÅŸturduÄŸumuzda, container Ã§alÄ±ÅŸÄ±r fakat container iÃ§erisindeki, uygulama hemen ayaÄŸa kalkmayabilir. Ã–n hazÄ±rlÄ±klarÄ± yapmasÄ± gerekebilir. Bir yerden dosya Ã§ekmesi gerekebilir. kÄ±sacasÄ± uygulama container Ã§alÄ±ÅŸtÄ±ktan sonra, hemen hizmet vermeyebilir. EÄŸer Liveness probe hemen baÅŸlatÄ±rsak, daha henÃ¼z uygulama hazÄ±r olmadÄ±ÄŸÄ± iÃ§in hata alacaktÄ±r. Ve hemen container restart edilecektir. DolayÄ±sÄ±yla daha tam anlamÄ±yla hizmet sunmadan fail edecek ve sÃ¼rekli restart olacaktÄ±r.

Bunu Ã¶nlemek adÄ±na, initialDelaySeconds parametresini kullanÄ±yoruz. Ve liveness probe 'a ÅŸunu diyoruz. Container baÅŸladÄ±ktan sonra, burada belirttiÄŸimiz sÃ¼re sonuna kadar bekle ardÄ±ndan saÄŸlÄ±k kontrolÃ¼ne baÅŸla.&#x20;

PeriodSeconds ile, bu saÄŸlÄ±k kontrolÃ¼nÃ¼n kaÃ§ saniye aralÄ±klarla yapÄ±lacaÄŸÄ±nÄ± belirtiyoruz. Yani container baÅŸladÄ±, initialdelaySeconds sÃ¼resi boyunca bekledi, ardÄ±ndan httpget ile liveness check yapmaya baÅŸladÄ±. 1. sorgusunu yaptÄ± cevap olumlu, 2. sorguyu gÃ¶ndermeden Periodseconds da belirlediÄŸimiz sÃ¼re boyunca bekledi, sonrasÄ±nda tekrar sorgu yaptÄ±. Bu dÃ¶ngÃ¼ bu ÅŸekilde devam edecek. Sorgular arasÄ± kaÃ§ar saniye beklemesini istiyorsak, periodSeconds parametresi ile belirtiyoruz.

2 - Exec (Komut yÃ¼rÃ¼tme)

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
```

HTTP uygulamalarÄ±mÄ±zÄ± httpget ile kontrol edebiliyoruz. Ancak uygulamalarÄ±mÄ±z http uygulamasÄ± deÄŸilse, bir konsol uygulamasÄ± vb. ise. Bunu httpget ile sorgulamamÄ±z mÃ¼mkÃ¼n deÄŸil.&#x20;

Bunun yerine, bir script yazar, o script iÃ§erisinde uygulamamÄ±za uygu sorgulama neyse, misal bir dosyanÄ±n olup, olmadÄ±ÄŸÄ±nÄ± kontrol edebiliriz. Ya da bir baÅŸka process 'in Ã§alÄ±ÅŸÄ±p, Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol edebiliriz. UygulamamÄ±za uygun saÄŸlÄ±k kontrolÃ¼nÃ¼ seÃ§eriz.

Liveness Probe altÄ±nda httpGet dÄ±ÅŸÄ±nda kullanabileceÄŸimiz probe olan EXEC bize bu imkanÄ± verir. Exec ile shell 'de, komut yada uygulama Ã§alÄ±ÅŸtÄ±rÄ±rÄ±z. Bu uygulama(komut) bize 0 kodu dÃ¶nerse, yani olumlu bir cevap verirse, saÄŸlÄ±klÄ± olduÄŸunu anlar. Bunun dÄ±ÅŸÄ±nda bir cevap dÃ¶nerse, problemli olarak iÅŸaretler ve container 'Ä± restart eder. YukarÄ±da ki Ã¶rnekte exec probe ile bir komut Ã§alÄ±ÅŸtÄ±rÄ±yoruz. cat komutu ile /tmp/healty dosyasÄ±nÄ± kontrol ediyoruz. EÄŸer, tmp dizininde bÃ¶yle bir dosya varsa, bize bu komutun sonucu 0 dÃ¶necektir ve olumlu olacaktÄ±r. BÃ¶yle bir dosya yoksa, exit code 1 olacak. Yani burada bir dosyanÄ±n olup, olmadÄ±ÄŸÄ±nÄ± kontrol ederek, uygulamanÄ±n saÄŸlÄ±klÄ± Ã§alÄ±ÅŸÄ±p, Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol ediyoruz.

3 - TCPSocket

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: goproxy
  labels:
    app: goproxy
spec:
  containers:
  - name: goproxy
    image: k8s.gcr.io/goproxy:0.1
    ports:
    - containerPort: 8080
    livenessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 15
      periodSeconds: 20
```

Bazen httpget isteÄŸi ve komut Ã§alÄ±ÅŸtÄ±rmak, bir ÅŸeyin saÄŸlÄ±klÄ± olup, olmadÄ±ÄŸÄ±nÄ± anlamamÄ±za yardÄ±mcÄ± olmaz.

Misal bir mySQL veritabanÄ± container Ã§alÄ±ÅŸtÄ±rÄ±yoruz. mysql process 3306 portundan eriÅŸilebilir. Biz de TCPSocket ile bu porta bir istek gÃ¶nderip, eÄŸer cevap alÄ±rsak uygulamanÄ±n dÃ¼zgÃ¼n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± varsayabiliriz. Olumsuz cevap alÄ±rsak, porta eriÅŸemezsek container restart edilecek.



### Readiness Probe

Senaryo ;

3 frontend podumuzu oluÅŸturacak bir deploymentÄ±mÄ±z, bu podlara dÄ±ÅŸ dÃ¼nyadan eriÅŸilebilmesini saÄŸlayacak Load Balancer tipi bir service mevcut. Biz tÃ¼m bunlarÄ± yaml dosyasÄ± arayÄ±cÄ±lÄ±ÄŸÄ±yla oluÅŸturduk ve apply ettik. Ve ortamÄ±mÄ±z Ã§alÄ±ÅŸmaya baÅŸladÄ±. Load Balancer IP adresi Ã¼zerinden kullanÄ±cÄ±lar bu frontend podlarÄ±mÄ±za eriÅŸip, web sitemize gelebiliyorlar.

Åimdi gelin deployment objesinde gÃ¼ncelleme yapalÄ±m. Diyelim ki, web sitemizin bulunduÄŸu imajÄ± gÃ¼ncelledik ve deploymentÄ±mÄ±zÄ± yeniden apply ettik. rolling-update stratejisi ile, podlar sÄ±rayla devreden Ã§Ä±karlÄ±p, yeni podlar devreye alÄ±ndÄ±.

Burada olanlarÄ± yakÄ±ndan inceleyelim;

Deployment da yeni bir imaj atadÄ±ÄŸÄ±mÄ±z zaman kubernetes hemen bu gÃ¼ncel imaj ile pod oluÅŸturarak, bu yeni podlarÄ± Load Balancer servisine dahil edecek.

Yani oluÅŸturulup, baÅŸlatÄ±ldÄ±ÄŸÄ± anda dÄ±ÅŸ dÃ¼nyadan bu podlara eriÅŸilebilinir olacak. Ya bizim uygulamamÄ±z ilk baÅŸladÄ±ÄŸÄ± anda, bir yerlere baÄŸlanÄ±p, bazÄ± dosyalarÄ± Ã§ekiyor ve sonrasÄ±nda web sitemizi sunmaya baÅŸlÄ±yorsa, Yada baÅŸka bir nedenden dolayÄ± container baÅŸlatÄ±lÄ±r, baÅŸlatÄ±lmaz bu uygulama hizmet veremiyorsa,  aradan belirli bir zaman geÃ§ip, bazÄ± iÅŸlemler yapmasÄ± gerekiyorsa, EÄŸer durum bu ise, bu podlarÄ± oluÅŸturulduÄŸumuz anda, bu podlar LoadBalancer servisinden trafik almaya baÅŸladÄ±ÄŸÄ± iÃ§in problem Ã§Ä±kacaktÄ±r.

Yani pod ayakta iÃ§indeki uygulama Ã§alÄ±ÅŸÄ±yor ancak, web sitemizi sunmaya hazÄ±r deÄŸil. DolayÄ±sÄ±yla bu pod, LoadBalancer servisine eklenmek iÃ§in hazÄ±r deÄŸil. Peki bu pod 'un Load Balancer servisinden trafik almaya hazÄ±r olduÄŸunu nasÄ±l anlayacaÄŸÄ±z? Burada da, yardÄ±mÄ±mÄ±za Readiness probe yetiÅŸiyor.

Kubelet, bir containerÄ±n trafiÄŸi kabul etmeye hazÄ±r olduÄŸunu bilmek iÃ§in, readiness probelarÄ± kullanÄ±r. Bir pod, tÃ¼m containerlar hazÄ±r olduÄŸunda, hazÄ±r kabul edilir. Readiness probe sayesinde, bir pod hazÄ±r olana kadar, service arkasÄ±na eklenmez.

Readiness probelar, aynen liveness probelar gibi oluÅŸturulur. httpGet, Exec, TCPSocket olarak kurgulanabilir.

Biz bir readiness check tanÄ±mlarÄ±z. EÄŸer bu readiness check olumlu sonuÃ§ dÃ¶nÃ¼yorsa, Pod Service altÄ±na eklenir ve trafik alÄ±r. EÄŸer readiness check fail ediyorsa, bu pod service 'den Ã§Ä±karÄ±lÄ±r.

Ã–rneÄŸimize dÃ¶nersek, yeni imajÄ± tanÄ±mladÄ±k ve yeni podlar oluÅŸturuldu. Podlar Ã§alÄ±ÅŸmaya baÅŸladÄ±. Ama bu noktada load balancer service altÄ±na hemen eklenmedi. Podlar iÃ§erisinde readiness check mekanizmasÄ± Ã§alÄ±ÅŸmaya baÅŸladÄ± initialdelayseconds sÃ¼resi kadar  bekledi, sonra tanÄ±mladÄ±ÄŸÄ±mÄ±z probe ile kontrolÃ¼nÃ¼ yaptÄ±. Olumlu cevap aldÄ±ÄŸÄ± anda, bu pod service arkasÄ±na eklenir ve trafik almaya baÅŸlar.

Readiness Check periodSeconds ile belirlenen sÃ¼re kadar, sÃ¼rede bir bu kontrolÃ¼nÃ¼ yapmaya devam eder. Fail edene kadar service arkasÄ±nda trafik alÄ±r. EÄŸer fail ederse, pod service endpoint listesinden Ã§Ä±karÄ±lÄ±r.&#x20;

Eski podlarÄ± direkt kapatmak yerine, kullanÄ±cÄ±lara hata gÃ¶stermemek iÃ§in. Bir pod terminate edileceÄŸi zaman. Bu poda yeni trafik gelmemesi iÃ§in pod service arkasÄ±ndan Ã§Ä±karÄ±lÄ±r. Service ile baÄŸlantÄ±sÄ± kesilir. BÃ¶ylece trafik almaz. Fakat kubernetes hemen bu podu kapatmaz. Ã‡Ã¼nkÃ¼ yeni trafik gelmese bile, bu pod halen eski istekleri iÅŸlemeye devam ediyor olabilir. Bu nedenle, bu iÅŸlemleri beklemesi gerekebilir.&#x20;

Pod tanÄ±mlarÄ±nda, terminationGracePeriodSeconds ÅŸeklinde bir parametre bulunur. Ve varsayÄ±lan olarak deÄŸeri 30 saniyedir.  Aksini belirtmediÄŸimiz sÃ¼rece bu deÄŸer kullanÄ±lÄ±r. Biz veya kubelet podu terminate istediÄŸimiz zaman podun iÃ§erisinde Ã§alÄ±ÅŸan master process ine hemen sigkill sinyali gÃ¶nderip hemen Ã¶ldÃ¼rmez. Bunun yerine sigturn sinyali gÃ¶nderir yani, yaptÄ±ÄŸÄ±n bir iÅŸlem varsa dÃ¼zgÃ¼n bir ÅŸekilde tamamla, bitince de kendini kapat sinyalini gÃ¶nderir. EÄŸer process bu sinyali aldÄ±ÄŸÄ±nda eÄŸer ortasÄ±nda olduÄŸu bir iÅŸ varsa, onu yapmayÄ± bÄ±rakmaz. O iÅŸlemi tamamlar ve bittikten sonra tÃ¼m baÄŸlantÄ±larÄ± dÃ¼zgÃ¼n bir ÅŸekilde kapatÄ±p sonrasÄ±nda da process de kapatÄ±lÄ±r.&#x20;

terminationGracePeriodSeconds sÃ¼resi, bu container a dÃ¼zgÃ¼n ÅŸekilde kendisini kapatabilmesi iÃ§in atadÄ±ÄŸÄ±mÄ±z bir sÃ¼redir. EÄŸer process bu sÃ¼re iÃ§erisinde dÃ¼zgÃ¼n bir ÅŸekilde kapatÄ±lÄ±rsa sÄ±kÄ±ntÄ± olmayacaktÄ±r. Fakat kapanmazsa da, bu sÃ¼re sonunda sigkill sinyali gÃ¶nderilip, zorla kapatÄ±lÄ±r. DolayÄ±sÄ±yla uygulamamÄ±zÄ±n ne kadar sÃ¼re iÃ§erisinde kapanabildiÄŸini bilmemiz o na gÃ¶re de terminationGracePeriodSeconds sÃ¼resini dÃ¼zenlememiz gerekebilir.

{% embed url="https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace" %}

Readiness AÅŸamalarÄ±,

1 - Deployment dosyasÄ± iÃ§erisinde imajÄ±mÄ±zÄ± gÃ¼ncelledik.

2- Yeni imajda, yeni bir pod oluÅŸturuldu.

3- Yeni pod Ã§alÄ±ÅŸmaya baÅŸladÄ±.

4- Readiness check mekanizmasÄ± Ã§alÄ±ÅŸmaya baÅŸladÄ±. initialdelayseconds sÃ¼resi kadar bekledi ve ardÄ±ndan ilk kontrolÃ¼nÃ¼ yaptÄ±.

5- Kontrol sonucu olumlu olduÄŸu anda, yeni pod service altÄ±na eklendi.

6- Eski pod henÃ¼z kapatÄ±lmadÄ±, EÄŸer iÅŸlemesi gereken istekler varsa, iÅŸlemeye devam ediyor. Ve yeni istekler gelmemesi iÃ§in service altÄ±ndan Ã§Ä±karÄ±ldÄ±.

7- Eski podun kendini dÃ¼zgÃ¼n kapatabilmesi iÃ§in, sigterm sinyali gÃ¶nderildi.

8- Eski pod Ã¼zerindeki iÅŸlemleri tamamladÄ±ktan sonra, kendini kapadÄ±.



Ã–rnek Readiness Probe Yaml iÃ§eriÄŸi;

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:
    team: development
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: blue
        ports:
        - containerPort: 80
        livenessProbe:
          httpGet:
            path: /healthcheck
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 20
          periodSeconds: 3
---
apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  selector:
    app: frontend
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
```

Readiness ve Liveness Probe 'lar aynÄ± anda kullanÄ±labilir.
