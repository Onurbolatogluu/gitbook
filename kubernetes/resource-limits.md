#  Resource Limits

Containerlar biz aksini belirtmediimiz s羹rece varsay覺lan olarak, 羹zerinde 癟al覺t覺klar覺 hostun CPU ve Memory kaynaklar覺na s覺n覺rs覺z ekilde eriirler. Yani biz 8 GB memory sahip bir sistem 羹zerinde container 癟al覺t覺rd覺覺m覺z zaman, bu container i癟erisindeki uygulama 8 GB memory 'nin tamam覺n覺 kullanabilir. Keza ayn覺 ekilde, t羹m CPU 癟ekirdeklerini de kullanabilir.&#x20;

Bu durum 繹zellikle kubernetes gibi y羹zlerce container 癟al覺t覺rd覺覺m覺z da覺t覺k yap覺larda, bizim i癟in sorun oluturur. Eer bir pod kotuu hostun 羹zerindeki t羹m kaynaklar覺 t羹ketiyorsa, bu dier podlar覺n ilerini d羹zg羹n yapmayaca覺 anlam覺na gelir. Bu nedenle, bu podlar覺n i癟erisinde 癟al覺an, containerlar覺n ne kadar cpu ve memory kullanabileceklerini k覺s覺tlamam覺z gerekmektedir. Pod tan覺mlar覺m覺zda, kullanabileceimiz request ve limit opsiyonlar覺 bize bu imkan覺 verir.

Cpu kayna覺, CPU birimleri olarak 繹l癟羹l羹r. Kubernetes de bir CPU una edeerdir;

* AWS vCPU
* GCP Core
* Azure vCore
* Hyperthread Bare-Metal

Kesirli deerlere izin verilir. 0.5 CPU talep eden, bir container 1 CPU talep eden, bir container '覺n, yar覺s覺 kadar CPU al覺r. Mili alam覺nda M son ekini kullanabiliriz.

rnein, 100m CPU, 100Milicpu ve 0.1 CPU ayn覺d覺r. 1M'den daha fazla ince hassasiyete izin verilmez. CPU her zaman, mutlak bir miktar olarak talep edilir. Asla g繹reli olarak talep edilmez.&#x20;

Misal;

1 CPU core kullanmak i癟in,

cpu:"1" = cpu="1000" = cpu:"1000m"

1 CPU 'nun %10nu kullanmas覺 i癟in,

cpu:"0.1" = cpu:"100" = cpu:"100m"



Kubernetes de CPU k覺s覺tlamalar覺 u ekilde ayarlan覺r;

Her worker node'un belirli CPU kaynaklar覺 mevcuttur. Bu kaynaklar cloud 羹st羹nde yada sanal olarak 癟alan stemlerde vCPU olarak, bare-metal sunucularda hyper thread olarak adland覺r覺l覺r.

Biz bir pod tan覺m覺na cpu:1 tan覺m覺 eklersek, O pod 'un 癟al覺t覺覺 node 羹st羹nde core'lardan, sadece 1 tanesini kullanaca覺 anlam覺na gelir. Baka bir yaz覺m ekli daha vard覺r. Her core 1000ms yani 1000mili cpu'luk g羹癟 demektir. Biz eer cpu:100m yaparsak, pod 癟al覺t覺覺 host 羹st羹nde 1 core'un 10'da 1' g羹c羹ne eriebilir anlam覺na gelecektir. Yani, cpu:1 ile cpu:1000m ayn覺 eydir. Keza 0.1 cpu ile cpu:100m de ayn覺d覺r.

Memory tan覺m覺 daha kolayd覺r;

Cluster da mevcut durumda kullan覺labilir bellek varsa, bir container belirlenen bellek isteini aabilir. Ancak bir container bellek s覺n覺r覺ndan fazlas覺n覺 kullanmas覺na izin verilmez.  Bir container s覺n覺r覺ndan daha fazla bellek ay覺r覺rsa, container sonland覺rma i癟in aday olur. Container limitinin 繹tesinde, bellek t羹ketmeye devam ederse, container sonland覺r覺l覺r. Sonland覺r覺lm覺 container yeniden balat覺labiliyorsa, dier herhangi bir runtime hatas覺 t羹r羹nde, olduu gibi kubelet onu yeniden balat覺r.

Container覺n kullanabilecei maksimum memory 'i, byte cinsinden tan覺mlayabiliriz. rnein, memory:64m dersek, bu container覺n, en fazla 64megabyte memory kullanmas覺na izin verdiimiz anlam覺na gelir.

Buradaki m: megabyte g:gigabyte k:kilobyte k覺saltmas覺d覺r. Bunlar覺n yerine memory hesaplamas覺nda kullan覺lan 2nin katlar覺n覺 kullanan g繹sterim ekli olan, kibibyte,mebibyte,gibibyte tan覺mlar覺da desteklenir.

CPU ve Memory k覺s覺tlama tan覺mlar覺n覺, iki ayr覺 b繹l羹mde tan覺mlayabiliyoruz. \
Bunlar, request ve limit parametreleri.

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: requestlimit
  name: requestlimit
spec:
  containers:
  - name: requestlimit
    image: obnet/stress
    resources:
      requests:
        memory: "64M"
        cpu: "250m"
      limits:
        memory: "256M"
        cpu: "0.5"
```

Request alt覺nda tan覺mlad覺覺m覺z deerler u anlama geliyor, Kubernetes bu pod'u oluturmaya balad覺覺 zaman, scheduler bu podun oluturaca覺 node se癟ecek. Bu se癟me aamas覺nda kubernetese unu diyoruz,  Bu podu en az 64megabyte memory, 250m milicpu yani 癟eyrek cpu core'un eriilebilir olduu bir node 羹zerinde olutur. K覺sacas覺 request k覺sm覺 bu podun oluturulabilmesi i癟in, minimum ne kadarl覺k bo kayna覺n olmas覺 gerektiini belirtiyor. Scheduler node se癟iminde bu parametreleri de g繹z 繹n羹ne alacak ve en az bu kadarl覺k kayna覺n bo olduu bir node se癟ecek. Eer bota 64mbyte memory ve  250m cpu sahip(癟eyrek cpu), bir node bulamazsa, bu pod oluturulmayacak.

Limit k覺sm覺 ise, tahmin edebileceiniz 羹zere, bu container覺n en fazla kullanabilecei sistem kayna覺n覺 belirtiyor. Yukar覺daki 繹rnekte unu diyoruz,

Bu pod i癟erisinde oluturulan container, en falza 256megabyte memory kullanabilsin, en 癟ok da yar覺m cpu (0.5) core 'na eriebilsin. G繹rd羹羹n羹z gibi cpu k覺sm覺n覺 istersek "0.5"  yada "1" gibi belirtebiliyor, yada "250m" gibi milicpu halinde yazabiliyoruz. Yani buradaki "0.5" yerine "500m" de yazsak ayn覺 olurdu.&#x20;

Bu podu oluturduumuz da u olacak, ncelikle scheduler 羹st羹nde en az 64megabyte memory ve 癟eyrek cpu core kayna覺n覺n bota olduu bir node bulacak, ve bu pod o node 羹zerinde oluturulacak. Pod oluturulacak ve container 癟al覺maya balayacak. Bu container ise, en fazla yar覺m cpu (0.5) core 'unun g羹c羹ne denk gelecek ekilde bir CPU kullanabilecek ve sistemden en fazla 256mbyte allocate edecek.

Bu Container eer yar覺m core 'dan fazla CPU kayna覺na erimek isterse ne olacak?

Bu durum m羹mk羹n olmayacak, CPU da belirlediimiz Limit neyse, bu container en fazla o kadar CPU kayna覺na eriebilecek.&#x20;

Memory k覺sm覺nda belirlediimiz deer, bu container覺n maksimum kullanabilecei memory deeridir. Fakat container bu deere geldii zaman, daha fazlas覺n覺 kullanamaz diye bir durum s繹z konusu deildir. Memory allocation CPU gibi 癟al覺m覺yor. teknik olarak farkl覺 eyler.

Bu nedenle, bu container i癟erisindeki uygulama sistemden daha fazla ram talebinde bulunabiliyor.  Sistem varsay覺lan olarak bunu engelleme ans覺na sahip deil. 襤te bu nedenle, eer container memory limitine geldiinde daha fazla memory allocate edilmesi i癟in bir mekanizma olmad覺覺ndan, bu duruma geldiinde OOMKilled (out off memory) kill durumuna ge癟erek restart ediliyor. Eer uygulamam覺z burada belirttiimiz, memory k覺s覺t覺ndan daha 癟ok memory talep ederse pod restart edilecek. Bu nedenle, bu k覺s覺tlar覺 uygulamam覺z覺n davran覺覺na g繹re belirlememizin davran覺覺na g繹re belirlememiz gerekiyor.

Kubernetes node'lar 羹st羹nde cpu ve memory kullan覺m覺n覺n kontrol edilmesi.

```bash
kubectl top node 
# kubectl top node "node_ismi" ile tekil bak覺labilir 
```

Kubernetes pod'lar 羹st羹nde cpu ve memory kullan覺m覺n覺n kontrol edilmesi.

```bash
kubectl top pod 
# kubectl top pod "pod_ismi" ile tekil bak覺labilir 
```

