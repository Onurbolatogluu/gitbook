---
description: persistent volume and persistent volume claim
---

#  PV/PVC

![](../.gitbook/assets/graphic-of-persistent-volume-bond.png)

Ephemeral volume b繹l羹m羹nde, podun yaam s羹resi boyunca saklamak ve yeni container oluturulduunda kaybetmemek istediimiz dosyalar覺 tutmak i癟in "emptydir" ve "hostpath" tipinde volumelerin nas覺l oluturulduunu g繹rm羹t羹k.

Bu yaz覺da, podun yaam s羹resinden ba覺ms覺z ekilde oluturabileceimiz volumeleri yani persistent volumeleri inceleyeceiz.

Sorun nedir?

襤lk olarak 3 node'lu bir cluster'm覺z olduunu d羹羹nelim. 3 node'lu cluster 羹zerinde mySQL bir veritaban覺 癟al覺t覺rmak istiyoruz. Bunun i癟in tek replika oluturacak deployment tasarlad覺k. Deployment i癟erisinde de mysql container'覺n veritaban覺 dosyalar覺n覺 tutaca覺 "emptyDir" tipinde bir volume oluturmak i癟in bir tan覺m girdik. Bu volume'u container'a mount edecek tan覺mlar覺da ekledikten sonra, Deployment objemizi oluturduk. mySQL container'dan oluan podumuz uygun bir worker node 羹zerinde oluturuldu ve 癟al覺maya balad覺. Bu nokta da eer container'da bir s覺k覺nt覺 olursa, kubelet yeni bir container oluturacak ve biz volume tan覺m覺n覺 da eklediimiz i癟in s覺k覺nt覺 癟覺kmadan 癟al覺maya devam edecek.

Ancak 繹yle bir senaryo d羹羹nelim;

Bu podun 癟al覺t覺覺 worker node da s覺k覺nt覺 癟覺kt覺 ve worker node devre d覺覺 kald覺. Podumuz deployment objesinin bir par癟as覺 olduu i癟in, Kubernetes bu durumu d羹zeltmek i癟in 癟al覺maya balayacak ve uygun olan worker node'lardan bir tanesi 羹zerinde yeni pod yarat覺lacak. Fakat bu durum ephemeral volume k覺sm覺nda da belirttiimiz uygulama i癟in s覺k覺nt覺 yaratm覺yorken, bu sefer mySQL veritaban覺m覺z i癟in problem oluturuyor. 羹nk羹 veritaban覺 羹zerinde ge癟ici, yeniden kolayca 羹retebileceimiz dosyalar覺 deil, uzun s羹re bar覺nd覺rmak zorunda olduumuz verileri tutuyor.

Pod'a ne olursa olsun, bu verileri kaybetmememiz gerekiyor. Pod'u oluturduk, mySQL container 癟al覺t覺 ve verileri "emptyDir" tipindeki volume'e yazmaya balad覺. Bu volume fiziksel olarak o container'覺n 癟al覺t覺覺 worker node 羹zerinde duruyor. Art覺k o worker node'a eriim gittii i癟in, Dolay覺s覺yla pod baka bir worker node 羹st羹nde yeniden oluturulduunda, bu dosyalara eriilemeyecek. Ve bu mySQL i癟in fazlas覺yla k繹t羹 bir senaryodur.

Bunun i癟in tek bir 癟繹z羹m var, bizim bu volume'leri cluster d覺覺nda duran, fakat t羹m worker node'lar taraf覺ndan ula覺labilen bir yerde oluturabiliyor olmam覺z laz覺m.

Eer bunu baarabilirsek, pod hangi node 羹zerine ta覺n覺rsa ta覺ns覺n, ayn覺 volume tekrar balayarak veri devaml覺l覺覺 salayabiliriz. Bu tarz cluster d覺覺nda tutulan 癟eitli t羹rde depolama 羹nitelerinin 羹zerinde, oluturabildiimiz ve pod yaam s羹resinden ba覺ms覺z ve daha uzun s羹re saklamam覺z gereken verileri saklamam覺za imkan veren volume'ler mevcut. Biz bunlara Persistent Volume diyoruz.

Persistent Volume nas覺l oluturuyoruz?

Bunun i癟in 繹ncelikle, bir ka癟 ayar yapmam覺z gerekiyor. 襤lk olarak volume oluturmak istediimiz depolama birimi ile cluster'm覺z覺n konuabiliyor olmas覺 gerekiyor.&#x20;

Bunun i癟inde cluster 羹st羹nde, bu depolama biriminin volume driver'lar覺n覺n y羹klenmesi gerekiyor. Kubernetes, NFS-ISCSI gibi un覺versal protokollere ait driver'lar覺n yan覺nda, AzureDisk-AzureFile-AWS EBS-Google PD-CEPHFS gibi bir 癟ok bulut servis salay覺c覺n覺n 繹zel storage 癟繹z羹mlerine ait driver'lar覺 b羹nyesinde bar覺nd覺r覺yor.

Yani Kubernetes, varsay覺lan olarak bu tiplerdeki depolama 癟繹z羹mleri ile konuabiliyor durumdad覺r. Fakat depolama 癟繹z羹mleri sadece bunlarla s覺n覺rl覺 deildir. Kubernetes bunlar覺n yan覺nda farkl覺 depolama 癟繹z羹mleri ile de konuabilecek yetenekleri, Container Storage Interface (CSI) adl覺 bir aray羹z ile sal覺yor.&#x20;

CSI, istee bal覺 blok ve dosya depolama sistemlerini Kubernetes gibi Container Orchestration'lar 羹zerindeki Container i y羹klerine maruz b覺rakmak i癟in bir standart olarak gelitirmitir. CSI'覺n benimsemesiyle kubernetes volume katman覺 geniletilebilir hale geldi. 3. taraf depolama salay覺c覺lar覺, CSI kullanarak 癟ekirdek kubernetes koduna dokunmak zorunda kalmadan Kubernetes'de yeni depolama sistemlerini a癟覺a 癟覺karan eklentiler yazabilme imkan覺na kavutu.

CSI, Kubernetes'in storage altyap覺s覺n覺n nas覺l ayarlanmas覺 gerektiini belirten bir standartt覺r. Depolama 癟繹z羹m羹 羹retenler, bu standart'a uygun driver'lar yazarak Kubernetes'in kendi alt yap覺lar覺yla da konuabilmelerine imkan salayabiliyorlar.

Yani 繹zetlersek, balanaca覺m覺z depolama birimi volume driver k覺sm覺nda sayd覺klar覺m覺zdan ise, (NFS,Azure,EBS) vb. bunlarla ilgili driver'lar hali haz覺rda Kubernetes 羹zerinde mevcut. Ancak bunlardan biri deilse, misal NetAPP firmas覺n覺n salad覺覺 depolama cihaz覺n覺 kullan覺yorsam da, bu sefer o firman覺n(NetAPP misal) bize salayaca覺 CSI driver'n覺n sisteme y羹klememiz gerekecektir.

襤lk ad覺m bu ekilde. ncelikle cluster ile depolama alt yap覺s覺n覺 birbirine bal覺yoruz ve bu ii halledip, Kubernetes cluster ile depolama birimini konuabilecek hale getirdikten sonra, bizler gidip bu depolama birimi 羹zerinde Kubernetes Cluster'm覺z alt覺nda kullanmak i癟in, depolama birimleri yarat覺yoruz. Sonras覺nda da bu depolama birimini kar覺l覺覺n覺 Kubernetes Cluster'm覺z alt覺nda, persistent volume isimli bir obje olarak oluturuyoruz.

rnekle, Kubernetes Cluster'm覺z覺n eriebildii NFS tabanl覺 bir depolama 癟繹z羹m羹m羹z olduunu varsayal覺m. Kubernetes alt覺nda, NFS driver'lar覺 bulunduu i癟in, ek bir driver y羹klememize gerek kalmadan bu 2 ortam birbirleri ile g繹r羹ebilir durumda. S覺rada ise, bu depolama 羹nitesi 羹zerinde, bizlerin eriip kullanabilecei, depolama birimleri oluturmakta. Bizler gidip NFS cihaz覺m覺za balan覺yor ve 繹rnein "tmp" ad覺nda bir payla覺m yarat覺yoruz. Bu ii de hallettikten sonra, s覺ra geldi bunun Kubernetes taraf覺nda kar覺l覺覺n覺 yaratmaya. 襤te bu nokta da oluturaca覺m覺z objenin ad覺 "Persistent Volume"dir.

![rnek PV yaml dosyas覺.](<../.gitbook/assets/Ekran g繹r羹nt羹s羹 2022-06-15 122020.png>)

Yukar覺da g繹rd羹羹n羹z gibi apiVersion: 1 olan, tipi de Persistent Volume olacak ekilde bir obje yarat覺yoruz. Spec k覺sm覺 balanaca覺m覺z depolama 羹nitesine balan覺rken, kullan覺lacak driver'a g繹re deiebilir.&#x20;

Burada driver'a g繹re deimeyen 3 se癟enek mevcut.

Capacity => Bu parametre bize ne kadarl覺k bir volume yaratmak istediimizi belirtiyor. Yukar覺daki 繹rnekte 5GB boyutunda bir volume oluturduumuz belirtilmi.

AccessMode => Bu volume'覺n ayn覺 anda birden fazla, pod'a baland覺覺 zaman, ne ekilde bir davran覺 sergileyeceini se癟iyoruz. Burada da se癟enekler 3'e ayr覺l覺yor.\
&#x20;   1- ReadWriteOnce=> Bu volume ayn覺 anda sadece tek bir pod'a balanabilir ve balanan pod hem     yazabilir hem de okuyabilir.\
&#x20;   2- ReadOnlyMany => Bu volume ayn覺 anda birden fazla poda balanabilir. Fakat podlar sadece bu volume de daha 繹nceden bu volume eklenmi dosyalar mevcut ise onlar覺 okuyabilirler. Dosya yazamazlar ve oluturamazlar.\
&#x20;   3- ReadWriteMany => Volume ayn覺 anda birden fazla pod'a balanarak, hem yazabilir hem okuyabilir.

Burada kulland覺覺m覺z se癟enekler, depolama 羹nitemizin ve driver'lar覺n yeteneklerine g繹re deiebilir.

rnein, Azure 羹zerinde AzureDisk kullan覺l覺rsa sadece "ReadWriteOnce" desteklenirken, AzureFile tipi bir storage ve driver kullan覺l覺rsa, bu sefer yukar覺da bahsettiim 3 se癟enee de destei mevcuttur.

PersistentVolumeReclaimPolicy => Burada bizler pod taraf覺ndan ii bitip, kullan覺lmay覺 b覺rakt覺ktan sonra, bu volume'e nas覺l davranaca覺n覺 belirtiyoruz. Burada, retain-recycle-delete se癟enekleri mevcuttur.

Retain se癟enei se癟ildii durumda, bu persistent volume kullan覺ld覺ktan sonra olduu gibi kal覺yor ve bizler buradaki dosyalar覺 manuel olarak kurtar覺p, baka bir yere ta覺ma imkan覺na kavuuyoruz.

Recycle se癟eneini se癟tiimiz durumda, bu sefer volume ile iimiz bittiinde volume silinmiyor, fakat i癟indeki t羹m dosyalar siliniyor. Bizler tekrar bo bir volume elde ederek baka ilerimizde kullanabiliyoruz.

Delete se癟eneini se癟tiimiz durumda, volume ile iimiz bittiinde volume tamamen siliniyor.

Yukar覺daki 繹rnei ele al覺rsak, NFS tabanl覺 eriim salayan 172.17.0.2 IP adresi 羹st羹nden eriilebilen bir depolama 羹nitesi 羹st羹ndeki "TMP" isimli payla覺m覺 kullanacak. 5GB boyutunda, sadece tek bir pod'a balanabilecek ve bu pod taraf覺ndan, hem dosya yazmak hem de okumak i癟in kullan覺labilen pod'un, ii bittii zaman i癟erisindeki dosyalar覺n silinecei app=mySQL labeline sahip bir persistent volume oluturuyoruz.

Bizler bir volume'羹 direkt olarak bir pod ile eletirme imkan覺na sahip deiliz. Biz bir persistent volume'羹 bir pod'a balamak i癟in 繹ncelikle Persistent Volume Claim tipinde bir obje daha yaratmam覺z gerekmektedir.

Persistent volume claim, bizlerin sistemde bulunan persistent volume'ler aras覺nda iimize uygun olan bir tanesini se癟memize yani bunu kullanmak ad覺na talep etmemize imkan veren objelerdir.



![Persistent Volume Claim i癟in 繹rnek yaml dosyas覺](<../.gitbook/assets/Ekran g繹r羹nt羹s羹 2022-06-15 124624.png>)

Yukar覺da g繹rd羹羹n羹z 羹zere, yine V1 api da bulunan, PersistentVolumeClaim tipinde bir obje yarat覺l覺yor. Spec k覺sm覺 Persistent volume'e 癟ok benziyor. Burada da, ne  kadarl覺k bir volume talep ettiimizi, hangi mode ile balanmak istediimizi belirtiyoruz. <mark style="color:red;">Son olarak "selector" k覺sm覺nda, bu persistent volume claim ile persistent volume'羹 label 羹st羹nden eletiriyoruz.</mark>

Persistent volume claim (volume talebi) app:mysql etiketine sahip, persistent volume taraf覺ndan salans覺n diyoruz.



Kubernetes neden depolama birimi oluturma ve bunu talep etme iini 2 farkl覺 obje 羹zerinden hallediyor?

Bunu 繹yle d羹羹nelim, bir developer olarak kulland覺覺m kubernetes cluster'覺 biz y繹netmiyor olabiliriz. Bizim iimiz olmayabilir ve bu ie bakan ayr覺 bir ekip olabilir. Dolay覺s覺yla oradaki ilemleri bizim bilmemiz m羹mk羹n olmayabilir.&#x20;

A firmas覺nda NFS tabanl覺 bir depolama 羹nitesi kullan覺yorken, B firmas覺nda ISCSI tabanl覺 bir depolama 羹nitesi kullan覺labilir. Bu ikisi i癟in "Persistent volume" ayarlar覺 deiik olabilir. An 繹nce persistent volume'den bahsederken de belirtmitik. "Spec" alt覺ndaki ayarlar depolama 羹nitelerine g繹re deiebilir. Dolay覺s覺yla bu volume oluturma iini Developer ekibine verirsek, her cihaz i癟in ayr覺 ayr覺 ayar yapmay覺 bilmesi gerekir. Bu da bir hayli zorlay覺c覺 olacakt覺r.

Kubernetes bu s覺k覺nt覺y覺 volume oluturma ve oluturulan volume'羹 talep etme iini ay覺rarak 癟繹zm羹t羹r. Persistent volume'ler, kubernetes cluster'覺 y繹neten ve depolama 羹nitelerine de eriimi olan sistem y繹neticileri veya cluster adminler taraf覺ndan oluturulur.

Bu ekip, ortama uygun depolama 羹r羹nlerinde gerekli ayarlamalar覺 yapar, kullan覺labilecek volume'leri oluturur, ard覺ndan developer ekibi, kendi podlar覺nda kullanmak ad覺na uygun 繹zelliklerde "persistent volume claim" yarat覺r. Bu claim'i, ne 癟eiit bir depolama 癟繹z羹m羹 ile kar覺lad覺覺m覺z developer ekibinin bilmesine gerek olan bir bilgi deildir.

Developer ekibi talebi oluturur, bu talep kimi yerlerde NFS depolama 羹niteleri ile, kimi yerlerde ISCSI ile 癟繹z羹m salan覺r.&#x20;

Persistent Volume Claim oluturulur, cluster da ki mevcut "persistent volume"lerden uygun olan bu talebi kar覺lar. Bu sayede depolama alt yap覺s覺n覺n ayarlanmas覺 ve talep edilmesi 2 farkl覺 ekip taraf覺ndan halledilebilir.

Ayr覺ca talep ve oluturma ad覺mlar覺 ayr覺ld覺覺 i癟in, tek bir talep yani "Persistent volume claim" tan覺m覺 bir 癟ok cluster da kullan覺labilir hale gelir ki, bu da uygulama ta覺nabilirliini salar.

Elimizde art覺k persistent volume yani (pv) bir de persistent volume claim (pvc) mevcut. Gelelim bunu pod'a balamaya,

![](<../.gitbook/assets/Ekran g繹r羹nt羹s羹 2022-06-15 130919.png>)

Pod tan覺m覺nda bizler kullanmak istediimiz volume'羹 talep eden, persistent volume claim ile bir ba kurar覺z. Pod tan覺mlar覺nda, "spec" parametresi alt覺nda yeni bir volume oluturur ve bunun hedefini oluturduumuz "persistent volume claim" olarak belirleriz. Sonras覺nda da bunu pod alt覺nda gerekli pathe mount ederiz. Bu pod oluturulduu anda bu talep devreye girer ve bu talebi kar覺layan Persistent volume" objesindeki tan覺ma g繹re, bu podun oluturulaca覺 worker node 羹zerinde ayarlamalar yap覺l覺r.

Storage cihaz覺na balan覺l覺r, arkada driver yapmas覺 gerekenleri yapar, sonucunda da bu pod, i癟erisindeki container'覺n ilgili pathine depolama cihaz覺 羹st羹nde duran, bu volume balan覺r.

Bu noktada itibaren, bu pathe yaz覺lan dosyalar asl覺nda bu volume'e yaz覺l覺r. Eer bu pod bulunduu worker node 羹st羹nden bir ekilde silinir, baka bir worker node'a ta覺n覺rsa, bu sefer ayn覺 ilemler, ta覺nd覺覺 worker node 羹zerinde ger癟ekletirilir. Ve yeni pod, bu volume'e balan覺r. Bu sayede podun yaam s羹resinden daha uzun s羹re boyunca veri saklayabileceimiz, alt yap覺ya kavumu oluruz.



{% code title="pv.yaml" %}
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
   name: mysqlpv
   labels:
     app: mysql
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  nfs:
    path: /
    server: 10.255.255.10
```
{% endcode %}

{% hint style="info" %}
Persistent volume cluster'dan balanabileceimiz, bir depolama 羹nitesindeki payla覺mlara veya diskleri kubernetes podlar覺na mount edebilmemize imkan sal覺yor.
{% endhint %}

pv.yaml => Yukar覺daki 繹rnekte, mysqlpv ad覺nda bir persistent volume oluturuyoruz. Burada bir de label at覺yoruz. Label k覺sm覺 繹nemli, 癟羹nk羹 persistent volume claim bu volume'羹 bu label'a g繹re se癟ecek. 5G alan talep ediyoruz. Volume tipi olarak ReadWriteOnce se癟iyoruz. En altta NFS sunucu IP adresi ve payla覺m覺n pathini belirtiyoruz. Buradaki ayarlar balanaca覺m覺z depolama 羹nitesine g繹re, kullan覺lacak driver'a g繹re deiir.

{% hint style="info" %}
Persistent volume talep eden, persistent volume claim oluturmak gerekiyor. B繹ylelikle ilgili podlara bu volume'羹 balayabiliriz.
{% endhint %}

{% code title="pvc.yaml" %}
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysqlclaim
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 5Gi
  storageClassName: ""
  selector:
    matchLabels:
      app: mysql
```
{% endcode %}

pvc.yaml => mysqlclaim ad覺nda bir persistent volume claim oluturuyoruz. Burada belirttiimiz access moduda persistent volume tan覺m覺 ile ayn覺 olmak zorundad覺r. Storage k覺sm覺nda talep edilen alan mevcuttur. "selector" k覺sm覺 ile "matchLabels" kullan覺larak "app:mysql" labeline sahip persistent volume se癟iyoruz. Hangi "Persistent Volume"羹 talep ettiimizi burada belirtiyoruz(Label-Selector).

{% code title="deploy.yaml" %}
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysqlsecret
type: Opaque
stringData:
  password: P@ssw0rd!
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysqldeployment
  labels:
    app: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - name: mysql
          image: mysql
          ports:
            - containerPort: 3306
          volumeMounts:
            - mountPath: "/var/lib/mysql"
              name: mysqlvolume
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysqlsecret
                  key: password
      volumes:
        - name: mysqlvolume
          persistentVolumeClaim:
            claimName: mysqlclaim
```
{% endcode %}

deploy.yaml => (Pod tan覺m覺 ve volume'羹 pod'a mount etmek) "mysqlvolume" ad覺nda volume tan覺ml覺yoruz. Bu volume'de "mysqlclaim" isimli "persistent volume claim"den salanmas覺n覺 talep ediyoruz. Ard覺ndan, "volumeMounts" parametresi ile pod'un "/var/lib/mysql" pathine mount ediyoruz.
