# ğŸ Examining the data of our Python application

```python
import http.server
from prometheus_client import start_http_server # For Prometheus

APP_PORT = 8000
METRICS_PORT = 8001 # For Prometheus

class HandleRequests(http.server.BaseHTTPRequestHandler):

    def do_GET(self):
        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(bytes("<html><head><title>First Application</title></head><body style='color: #333; margin-top: 30px;'><center><h2>Welcome to our first Prometheus-Python application.</center></h2></body></html>", "utf-8"))
        self.wfile.close()

if __name__ == "__main__":
    start_http_server(METRICS_PORT) # For Prometheus
    server = http.server.HTTPServer(('10.90.0.144', APP_PORT), HandleRequests)
    server.serve_forever()

```

YukarÄ±daki uygulama, Prometheus metriklerini kullanarak bir HTTP sunucusu baÅŸlatan basit bir uygulamadÄ±r. UygulamanÄ±n detaylarÄ±na inecek olursak;



1. Ä°lk olarak, gerekli modÃ¼ller ve kÃ¼tÃ¼phaneler iÃ§e aktarÄ±lÄ±r:
   * `http.server`: Bu modÃ¼l, temel bir HTTP sunucusu oluÅŸturmak iÃ§in kullanÄ±lÄ±r.
   * `prometheus_client`: Prometheus metriklerini yayÄ±nlamak iÃ§in kullanÄ±lan bir kÃ¼tÃ¼phanedir.
2. ArdÄ±ndan, uygulama ve metrikler iÃ§in iki farklÄ± port numarasÄ± belirlenir:
   * `APP_PORT`: UygulamanÄ±n dinleyeceÄŸi port numarasÄ± (8000).
   * `METRICS_PORT`: Prometheus metriklerinin yayÄ±nlanacaÄŸÄ± port numarasÄ± (8001).
3. `HandleRequests` adÄ±nda bir sÄ±nÄ±f tanÄ±mlanÄ±r. Bu sÄ±nÄ±f, `http.server.BaseHTTPRequestHandler` sÄ±nÄ±fÄ±ndan tÃ¼retilmiÅŸtir ve gelen HTTP isteklerini iÅŸlemek iÃ§in kullanÄ±lÄ±r. Åu anda sadece `GET` isteklerini ele alacak ÅŸekilde tanÄ±mlanmÄ±ÅŸtÄ±r.
4. `do_GET` metodunda, sunucu, baÅŸarÄ±lÄ± bir yanÄ±t olarak `200` durum kodunu gÃ¶nderir. Daha sonra yanÄ±tÄ±n iÃ§eriÄŸine HTML metni ekler ve baÄŸlantÄ±yÄ± kapatÄ±r. Bu HTML metni, kullanÄ±cÄ±ya "Welcome to our first Prometheus-Python application." mesajÄ±nÄ± gÃ¶sterir.
5. `__main__` iÃ§inde, metrikleri toplamak ve yayÄ±nlamak iÃ§in Prometheus istemcisini baÅŸlatÄ±rÄ±z: `start_http_server(METRICS_PORT)`.
6. Daha sonra, HTTP sunucusunu baÅŸlatÄ±rÄ±z. Sunucunun IP adresi (`10.90.0.144`) ve uygulama portu (`APP_PORT`) ile `http.server.HTTPServer` sÄ±nÄ±fÄ±ndan bir nesne oluÅŸtururuz. Bu nesneye, istekleri iÅŸlemek iÃ§in `HandleRequests` sÄ±nÄ±fÄ±nÄ± saÄŸlarÄ±z.
7. Son olarak, `server.serve_forever()` ile sunucuyu sÃ¼rekli Ã§alÄ±ÅŸÄ±r durumda tutarÄ±z. Bu sayede sunucu, gelen isteklere sÃ¼rekli olarak yanÄ±t verebilir.

Ã–zetle, bu uygulama, temel bir HTTP sunucusu baÅŸlatÄ±r ve Prometheus istemcisi kullanarak metrikleri toplar ve yayÄ±nlar.

```bash
/usr/bin/python3 app.py
```

UygulamamÄ±zÄ± Ã§alÄ±ÅŸtÄ±rÄ±yoruz.

{% hint style="info" %}
`prometheus_client` paketi, uygulamalarÄ±mÄ±zda Prometheus metriklerini toplamamÄ±zÄ± ve sunmamÄ±zÄ± saÄŸlayan bir kÃ¼tÃ¼phanedir.
{% endhint %}

.

.

.

ArdÄ±ndan python uygulamamÄ±zÄ±, prometheus arayÃ¼zÃ¼nden metriklerini incelemek ve olasÄ± problemleri tespit etmek iÃ§in, UygulamamÄ±zÄ±n kodunda expose ettiÄŸimiz metrik portunu prometheus.yml dosyasÄ±na target olarak ekliyoruz.

```yaml
  - job_name: "prom_python_app"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
      - targets: ["10.90.0.144:8001"]
```

ArdÄ±ndan prometheus servisini yeniden baÅŸlatÄ±p, arayÃ¼zden verinin kontrolÃ¼nÃ¼ saÄŸlÄ±yoruz.

<figure><img src="../.gitbook/assets/WhatsApp Image 2023-04-05 at 15.01.39.jpeg" alt=""><figcaption></figcaption></figure>



#### Counter Metrics

```python
import http.server
import random
from prometheus_client import start_http_server, Counter # For prometheus and counter metrics

REQUEST_COUNT = Counter('app_requests_count_istekler', 'total app http request count',['app_name', 'endpoint']) # Prometheus for counter metrics
RANDOM_COUNT = Counter('app_rastgele_count','increment counter by random value') # Prometheus for counter metrics

APP_PORT = 8000
METRICS_PORT = 8001 # for Prometheus

class HandleRequests(http.server.BaseHTTPRequestHandler):

    def do_GET(self):
        REQUEST_COUNT.labels('prom_python_app', self.path).inc() # Prometheus for counter metrics
        random_val = random.random()*10 # Prometheus for counter metrics
        RANDOM_COUNT.inc(random_val) # Prometheus for counter metrics

        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(bytes("<html><head><title>First Application</title></head><body style='color: #333; margin-top: 30px;'><center><h2>Welcome to our first Prometheus-Python application.</center></h2></body></html>", "utf-8"))
        self.wfile.close()

if __name__ == "__main__":
    start_http_server(METRICS_PORT)  # for Prometheus
    server = http.server.HTTPServer(('10.90.0.144', APP_PORT), HandleRequests)
    server.serve_forever()
```

Kodumuza, gelen istekleri inceleyebilmek iÃ§in, bazÄ± satÄ±rlarÄ± ekliyoruz. Bu satÄ±rlarÄ±n aÃ§Ä±klamalarÄ± ÅŸu ÅŸekilde,&#x20;

1. `random` modÃ¼lÃ¼ iÃ§e aktarÄ±ldÄ±. Bu modÃ¼l, rastgele sayÄ±lar Ã¼retmek iÃ§in kullanÄ±lÄ±r.
2. Prometheus istemcisinden `Counter` metriÄŸi iÃ§e aktarÄ±ldÄ±. Counter, artan bir deÄŸeri temsil eden bir metrik tÃ¼rÃ¼dÃ¼r.
3. Ä°ki adet Counter metriÄŸi tanÄ±mlandÄ±:
   * `REQUEST_COUNT`: UygulamanÄ±n aldÄ±ÄŸÄ± HTTP isteklerinin sayÄ±sÄ±nÄ± takip eder. Bu metrik, 'app\_name' ve 'endpoint' etiketleri ile etiketlendi.
   * `RANDOM_COUNT`: Rastgele bir deÄŸerle artÄ±rÄ±lan bir sayaÃ§tÄ±r.
4. `do_GET` metodunda, iki metrik gÃ¼ncellenir:
   * Ä°lk olarak, `REQUEST_COUNT` metriÄŸi etiketlerle birlikte artÄ±rÄ±lÄ±r (`inc()` fonksiyonu ile). Bu, uygulamanÄ±n adÄ± ve istek yolu ile etiketlenmiÅŸ her HTTP isteÄŸi iÃ§in sayaÃ§ deÄŸerini bir artÄ±rÄ±r.
   * Daha sonra, `random.random()` fonksiyonu kullanÄ±larak 0 ile 1 arasÄ±nda rastgele bir sayÄ± Ã¼retiliyor. Bu sayÄ±yÄ± 10 ile Ã§arparak 0 ile 10 arasÄ±nda rastgele bir sayÄ± elde ediyoruz. Bu deÄŸer `random_val` adlÄ± deÄŸiÅŸkene atanÄ±yor.
   * ArdÄ±ndan, `RANDOM_COUNT.inc(random_val)` satÄ±rÄ±nda, `RANDOM_COUNT` adÄ±nda bir Prometheus Counter nesnesi bulunuyor. Counter, artan sayÄ±larÄ± tutmak iÃ§in kullanÄ±lÄ±r ve genellikle bir uygulamada gerÃ§ekleÅŸen belirli olaylarÄ±n sayÄ±sÄ±nÄ± izlemek iÃ§in kullanÄ±lÄ±r. Bu Ã¶rnekte, `RANDOM_COUNT` adlÄ± Counter nesnesine `inc()` fonksiyonu ile `random_val` deÄŸiÅŸkeninde tutulan rastgele deÄŸeri ekliyoruz. Bu, Counter nesnesinin deÄŸerini `random_val` kadar artÄ±rÄ±r.

<figure><img src="../.gitbook/assets/image (89).png" alt=""><figcaption></figcaption></figure>

Yeni eklenen kod parÃ§alarÄ± sayesinde, uygulamanÄ±n aldÄ±ÄŸÄ± HTTP istek sayÄ±sÄ±nÄ± ve rastgele deÄŸerlerle artan bir sayacÄ± takip etmek mÃ¼mkÃ¼n hale gelmiÅŸtir. Bu metrikler, Prometheus tarafÄ±ndan toplanarak uygulamanÄ±n performansÄ± ve iÅŸlem sayÄ±sÄ± hakkÄ±nda daha fazla bilgi saÄŸlar.

UygulamamÄ±za ilgili satÄ±rlarÄ± ekledikten sonra tekrar start ediyoruz ve prometheus ara yÃ¼zÃ¼nde yeni verileri inceliyoruz.

<figure><img src="../.gitbook/assets/image (45).png" alt=""><figcaption></figcaption></figure>

BÃ¶ylelikle uygulamamÄ±za yapÄ±lan isteklerin miktarÄ±nÄ± gÃ¶rebiliyoruz.

.

.

.

#### Gauge Metrics

<pre class="language-python"><code class="lang-python">import http.server
import random
import time
from prometheus_client import start_http_server, Gauge

REQUEST_INPROGRESS = Gauge('app_requests_inprogress','number of application requests in progress')
REQUEST_LAST_SERVED = Gauge('app_last_served', 'Time the application was last served.')

APP_PORT = 8000
METRICS_PORT = 8001

class HandleRequests(http.server.BaseHTTPRequestHandler):

    @REQUEST_INPROGRESS.track_inprogress()
    # track_inprogress() yÃ¶ntemi, Prometheus'un Gauge sÄ±nÄ±fÄ±nÄ±n bir yÃ¶ntemidir.
<strong>    # Bu, her seferinde bir istek alÄ±ndÄ±ÄŸÄ±nda ve do_GET fonksiyonu Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, REQUEST_INPROGRESS Gauge metriÄŸinin deÄŸeri otomatik olarak artÄ±rÄ±lÄ±r. 
</strong><strong>    # Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda ve fonksiyon sona erdiÄŸinde ise deÄŸer otomatik olarak azaltÄ±lÄ±r. 
</strong><strong>    # Bu, ÅŸu anda iÅŸlenmekte olan isteklerin sayÄ±sÄ±nÄ± takip etmeye ve uygulamanÄ±n ne kadar yÃ¼k altÄ±nda olduÄŸunu anlamaya yardÄ±mcÄ± olur.
</strong>    def do_GET(self):
        time.sleep(5)
        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(bytes("&#x3C;html>&#x3C;head>&#x3C;title>First Application&#x3C;/title>&#x3C;/head>&#x3C;body style='color: #333; margin-top: 30px;'>&#x3C;center>&#x3C;h2>Welcome to our first Prometheus-Python application.&#x3C;/center>&#x3C;/h2>&#x3C;/body>&#x3C;/html>", "utf-8"))
        self.wfile.close()
        REQUEST_LAST_SERVED.set_to_current_time()
        # set_to_current_time() fonksiyonu, Prometheus'un Gauge sÄ±nÄ±fÄ±nÄ±n bir yÃ¶ntemidir. 
        # Bu yÃ¶ntem, Gauge metriÄŸini otomatik olarak mevcut zamanla gÃ¼nceller (Unix epoch formatÄ±nda, saniye cinsinden). 
        # Bu sayede, uygulama sÃ¼resince en son iÅŸlenen isteÄŸin zamanÄ±nÄ± takip edebilir ve uygulamanÄ±n ne kadar sÃ¼reyle aktif olduÄŸunu gÃ¶rebilirsiniz.

if __name__ == "__main__":
    start_http_server(METRICS_PORT)
    server = http.server.HTTPServer(('10.90.0.144', APP_PORT), HandleRequests)
    server.serve_forever()
</code></pre>

Gauge metrikleri, bir deÄŸeri artÄ±rabilen, azaltabilen veya belirli bir deÄŸere ayarlayabilen metriklerdir. Bu kod parÃ§asÄ±nda iki Gauge metrik tanÄ±mlanmÄ±ÅŸtÄ±r:



1. REQUEST\_INPROGRESS: Bu metrik, ÅŸu anda iÅŸlenmekte olan uygulama isteklerinin sayÄ±sÄ±nÄ± temsil eder. 'app\_requests\_inprogress' adÄ±yla ve 'number of application requests in progress' aÃ§Ä±klamasÄ±yla tanÄ±mlanmÄ±ÅŸtÄ±r.

```python
REQUEST_INPROGRESS = Gauge('app_requests_inprogress','number of application requests in progress')
```

2. REQUEST\_LAST\_SERVED: Bu metrik, uygulamanÄ±n en son ne zaman hizmet verdiÄŸini gÃ¶sterir. 'app\_last\_served' adÄ±yla ve 'Time the application was last served.' aÃ§Ä±klamasÄ±yla tanÄ±mlanmÄ±ÅŸtÄ±r.

```python
REQUEST_LAST_SERVED = Gauge('app_last_served', 'Time the application was last served.')
```

Ä°lk Gauge metriÄŸi, `REQUEST_INPROGRESS`, `do_GET` fonksiyonu iÃ§in bir dekoratÃ¶r olarak kullanÄ±lÄ±r. Bu sayede, fonksiyonun baÅŸÄ±nda ve sonunda otomatik olarak Gauge deÄŸeri gÃ¼ncellenir. Bu, iÅŸlem sÃ¼resi boyunca kaÃ§ isteÄŸin olduÄŸunu takip etmeye yardÄ±mcÄ± olur.

```python
@REQUEST_INPROGRESS.track_inprogress()
def do_GET(self):
    ...
```

Ä°kinci Gauge metriÄŸi, `REQUEST_LAST_SERVED`, `do_GET` fonksiyonunun sonunda kullanÄ±lÄ±r. UygulamanÄ±n en son ne zaman hizmet verdiÄŸini belirlemek iÃ§in ÅŸu anki zamanÄ± bu metriÄŸe ayarlar.

```python
REQUEST_LAST_SERVED.set_to_current_time()
```

Bu Ã¶lÃ§Ã¼mler sayesinde, uygulamanÄ±n performansÄ±nÄ± ve kullanÄ±mÄ±nÄ± daha iyi anlayabilir ve gerektiÄŸinde iyileÅŸtirmeler yapabilirsiniz.



<figure><img src="../.gitbook/assets/image (72).png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (42).png" alt=""><figcaption><p><code>time() - app_last_served</code> PromQL sorgusu, ÅŸu anki zaman ile <code>app_last_served</code> adlÄ± Gauge metriÄŸinin deÄŸeri arasÄ±ndaki farkÄ± hesaplamak iÃ§in kullanÄ±lÄ±r. Bu sorgu, uygulamanÄ±n en son isteÄŸi iÅŸleyip hizmet verdiÄŸi zamanÄ±n ne kadar Ã¶nce olduÄŸunu belirlemeye yardÄ±mcÄ± olur.</p></figcaption></figure>

.

.

.

#### Summary Metrics

```python
import http.server
import time
from prometheus_client import start_http_server, Summary

REQUEST_RESPOND_TIME = Summary('app_response_latency_seconds', 'Response latency in seconds')

APP_PORT = 8000
METRICS_PORT = 8001

class HandleRequests(http.server.BaseHTTPRequestHandler):

    @REQUEST_RESPOND_TIME.time()
    def do_GET(self):
        time.sleep(6)
        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(bytes("<html><head><title>First Application</title></head><body style='color: #333; margin-top: 30px;'><center><h2>Welcome to our first Prometheus-Python application.</center></h2></body></html>", "utf-8"))
        self.wfile.close()


if __name__ == "__main__":
    start_http_server(METRICS_PORT)
    server = http.server.HTTPServer(('10.90.0.144', APP_PORT), HandleRequests)
    server.serve_forever()
```

YukarÄ±da summary metriÄŸini tanÄ±mladÄ±ÄŸÄ±mÄ±z kod bloÄŸu mevcut. Uygulama kodumuza eklediÄŸimiz 2 farklÄ± satÄ±r mevcut. Bu satÄ±rlarÄ± aÃ§Ä±klamak gerekirse;

1. `Summary` metriÄŸi tanÄ±mlama:

```python
REQUEST_RESPOND_TIME = Summary('app_response_latency_seconds', 'Response latency in seconds')
```

Bu satÄ±rda, `Summary` tipinde bir metrik nesnesi oluÅŸturuyoruz. `Summary` metriÄŸi, gÃ¶zlem sÃ¼resi boyunca olaylarÄ±n sÃ¼relerinin veya boyutlarÄ±nÄ±n istatistiksel Ã¶zetini saÄŸlar. Burada, `app_response_latency_seconds` adÄ±nda bir metrik tanÄ±mlÄ±yoruz ve bu metriÄŸin aÃ§Ä±klamasÄ± olarak "Response latency in seconds" kullanÄ±yoruz.

2. `time()` dekoratÃ¶rÃ¼nÃ¼ kullanma:

```python
@REQUEST_RESPOND_TIME.time()
```

`time()` dekoratÃ¶rÃ¼, Python'daki dekoratÃ¶rlerle ilgilidir. DekoratÃ¶rler, fonksiyonlarÄ±n veya sÄ±nÄ±f metotlarÄ±nÄ±n davranÄ±ÅŸÄ±nÄ± deÄŸiÅŸtirmek veya geniÅŸletmek iÃ§in kullanÄ±lÄ±r. Bu Ã¶rnekte, `time()` dekoratÃ¶rÃ¼ `do_GET` metodu Ã¼zerinde kullanÄ±larak, metot Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda sÃ¼re Ã¶lÃ§Ã¼mÃ¼ yapÄ±lÄ±r ve sonuÃ§lar `REQUEST_RESPOND_TIME` metriÄŸine kaydedilir.

DekoratÃ¶rler, fonksiyonun veya metotun Ã¼zerinde `@` iÅŸareti ile belirtilir. Bu sayede, dekoratÃ¶rÃ¼n arkasÄ±ndaki fonksiyon veya metot, dekoratÃ¶rÃ¼n saÄŸladÄ±ÄŸÄ± ek Ã¶zelliklerle Ã§alÄ±ÅŸÄ±r. Bu durumda, `time()` dekoratÃ¶rÃ¼ `do_GET` metodunun Ã§alÄ±ÅŸma sÃ¼resini Ã¶lÃ§er ve bu sÃ¼reyi `REQUEST_RESPOND_TIME` metriÄŸine ekler.

```python
    @REQUEST_RESPOND_TIME.time()
    def do_GET(self):
        ...
```

Ã–zetle, `REQUEST_RESPOND_TIME = Summary(...)` satÄ±rÄ±yla, sÃ¼re Ã¶lÃ§Ã¼mlerini tutmak iÃ§in bir `Summary` metriÄŸi tanÄ±mlÄ±yoruz. `@REQUEST_RESPOND_TIME.time()` satÄ±rÄ±yla ise, bu metriÄŸi kullanarak `do_GET` metodunun Ã§alÄ±ÅŸma sÃ¼resini Ã¶lÃ§Ã¼yoruz. Bu sayede, uygulamanÄ±n yanÄ±t sÃ¼resi hakkÄ±nda istatistiksel Ã¶zetler elde ederiz.

{% hint style="info" %}
`@REQUEST_RESPOND_TIME.time()` kod parÃ§acÄ±ÄŸÄ±, asÄ±l olarak sÃ¼re Ã¶lÃ§Ã¼mÃ¼nÃ¼ yapmak ve bu sÃ¼reyi `REQUEST_RESPOND_TIME` metriÄŸine kaydetmekle ilgilidir. Bu dekoratÃ¶r, kodun Ã¼zerine yerleÅŸtirildiÄŸi `do_GET` metodu Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda, metodu Ã§alÄ±ÅŸtÄ±ran iÅŸlemi otomatik olarak Ã¶lÃ§er ve bu sÃ¼reyi `REQUEST_RESPOND_TIME` metriÄŸine ekler.

SonuÃ§ olarak, bu dekoratÃ¶r sayesinde uygulamanÄ±n yanÄ±t sÃ¼resi Ã¶lÃ§Ã¼mleri, Prometheus tarafÄ±ndan toplanarak analiz edilebilir ve izlenebilir hale gelir
{% endhint %}

<figure><img src="../.gitbook/assets/image (30).png" alt=""><figcaption></figcaption></figure>

Kodumuza 6 saniye gecikmesi iÃ§in "sleep" eklediÄŸimiz iÃ§in, ilk isteÄŸin response sÃ¼resi "6 sn" olarak gÃ¶zÃ¼kÃ¼yor. Fakat bu deÄŸiÅŸken sÃ¼rekli toplanarak ilerlediÄŸi iÃ§in, ortalama response sÃ¼resini incelememiz iÃ§in bize yardÄ±mcÄ± olmaz.

Ortalama yanÄ±t sÃ¼resini hesaplamak iÃ§in,&#x20;

```promql
rate(app_response_latency_seconds_sum[5m]) / rate(app_response_latency_seconds_count[5m])

```

1. `rate(app_response_latency_seconds_sum[5m])`: Son 5 dakika iÃ§indeki `app_response_latency_seconds_sum` metriÄŸinin deÄŸerinin artÄ±ÅŸ hÄ±zÄ±nÄ± hesaplar. Bu, son 5 dakika boyunca toplam sÃ¼relerin ne kadar hÄ±zla arttÄ±ÄŸÄ±nÄ± gÃ¶sterir.
2. `rate(app_response_latency_seconds_count[5m])`: Son 5 dakika iÃ§indeki `app_response_latency_seconds_count` metriÄŸinin deÄŸerinin artÄ±ÅŸ hÄ±zÄ±nÄ± hesaplar. Bu, son 5 dakika boyunca toplam istek sayÄ±sÄ±nÄ±n ne kadar hÄ±zla arttÄ±ÄŸÄ±nÄ± gÃ¶sterir.
3. Son olarak, bu iki deÄŸeri bÃ¶leriz.

<figure><img src="../.gitbook/assets/image (55).png" alt=""><figcaption></figcaption></figure>

Bu bÃ¶lme iÅŸlemi, son 5 dakika iÃ§indeki ortalama yanÄ±t sÃ¼resini verir. Ortalama yanÄ±t sÃ¼resi, toplam sÃ¼relerin artÄ±ÅŸ hÄ±zÄ±nÄ±n, istek sayÄ±sÄ±nÄ±n artÄ±ÅŸ hÄ±zÄ±na oranÄ± olarak hesaplanÄ±r. Bu sayede, son 5 dakikada gerÃ§ekleÅŸen isteklerin ortalama sÃ¼resini gÃ¶rebilirsiniz.



{% hint style="info" %}
`rate` fonksiyonu ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:

1. `rate` fonksiyonu, belirtilen zaman aralÄ±ÄŸÄ± (Ã¶rneÄŸin, son 5 dakika) boyunca metrik deÄŸerinin zaman serisindeki veri noktalarÄ±nÄ± alÄ±r.
2. Ä°ki ardÄ±ÅŸÄ±k veri noktasÄ± arasÄ±ndaki farkÄ± alarak, her bir veri noktasÄ± arasÄ±ndaki deÄŸiÅŸimi hesaplar.
3. Bu deÄŸiÅŸimlerin toplamÄ±nÄ± alÄ±r ve belirtilen zaman aralÄ±ÄŸÄ±na bÃ¶ler (Ã¶rneÄŸin, 5 dakika). Bu iÅŸlem, zaman aralÄ±ÄŸÄ± boyunca metrik deÄŸerindeki ortalama deÄŸiÅŸimi hesaplar.



Ã–rneÄŸin, `rate(app_response_latency_seconds_count[5m])` sorgusu iÃ§in:

1. Son 5 dakikadaki `app_response_latency_seconds_count` metriÄŸi iÃ§in veri noktalarÄ±nÄ± alÄ±r.
2. Ä°ki ardÄ±ÅŸÄ±k veri noktasÄ± arasÄ±ndaki farkÄ± alarak, her bir veri noktasÄ± arasÄ±ndaki deÄŸiÅŸimi hesaplar.
3. Bu deÄŸiÅŸimlerin toplamÄ±nÄ± alÄ±r ve 5 dakikaya bÃ¶ler. Bu iÅŸlem, son 5 dakika iÃ§inde iÅŸlenen istek sayÄ±sÄ±nÄ±n ortalama artÄ±ÅŸ hÄ±zÄ±nÄ± hesaplar.



SonuÃ§ olarak, `rate(app_response_latency_seconds_count[5m])` sorgusu, son 5 dakika iÃ§inde iÅŸlenen istek sayÄ±sÄ±nÄ±n ortalama artÄ±ÅŸ hÄ±zÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.&#x20;
{% endhint %}

.

.

.

#### Histogram Metrics

```promql
import http.server
import time
from prometheus_client import start_http_server, Histogram

REQUEST_RESPOND_TIME = Histogram('app_response_latency_seconds', 'Response latency in seconds', buckets=[0.1,0.5,1,2,3,4,5,10])

APP_PORT = 8000
METRICS_PORT = 8001

class HandleRequests(http.server.BaseHTTPRequestHandler):

    @REQUEST_RESPOND_TIME.time()
    def do_GET(self):
        time.sleep(1)
        self.send_response(200)
        self.send_header("Content-type", "text/html")
        self.end_headers()
        self.wfile.write(bytes("<html><head><title>First Application</title></head><body style='color: #333; margin-top: 30px;'><center><h2>Welcome to our first Prometheus-Python application.</center></h2></body></html>", "utf-8"))
        self.wfile.close()
        REQUEST_RESPOND_TIME.observe(time_taken)


if __name__ == "__main__":
    start_http_server(METRICS_PORT)
    server = http.server.HTTPServer(('10.90.0.144', APP_PORT), HandleRequests)
    server.serve_forever()
```

YukarÄ±daki kod parÃ§acÄ±ÄŸÄ±, Prometheus iÃ§in Histogram metrik tÃ¼rÃ¼ kullanarak uygulamanÄ±n HTTP isteklerine verdiÄŸi yanÄ±t sÃ¼relerini Ã¶lÃ§mektedir. Histogram metrikleri, belirli bir deÄŸer aralÄ±ÄŸÄ±nda meydana gelen olaylarÄ±n sayÄ±sÄ±nÄ± Ã¶lÃ§en ve bu olaylarÄ± belirli "kova" (bucket) adÄ± verilen aralÄ±klara gÃ¶re gruplandÄ±ran metriklerdir.

Kod parÃ§acÄ±ÄŸÄ±nda, Histogram metriÄŸi ÅŸu ÅŸekilde tanÄ±mlanmaktadÄ±r:

```python
REQUEST_RESPOND_TIME = Histogram('app_response_latency_seconds', 'Response latency in seconds', buckets=[0.1,0.5,1,2,3,4,5,10])
```

* `app_response_latency_seconds`: Histogram metriÄŸinin adÄ±dÄ±r.
* `'Response latency in seconds'`: Histogram metriÄŸinin aÃ§Ä±klamasÄ±dÄ±r.
* `buckets=[0.1,0.5,1,2,3,4,5,10]`: Histogram iÃ§in tanÄ±mlanan kova sÄ±nÄ±rlarÄ±dÄ±r. Bu, yanÄ±t sÃ¼relerini ÅŸu aralÄ±klara gÃ¶re gruplandÄ±racaktÄ±r: <= 0.1s, <= 0.5s, <= 1s, <= 2s, <= 3s, <= 4s, <= 5s, <= 10s ve > 10s.

Histogram metriÄŸi kullanarak yanÄ±t sÃ¼relerini Ã¶lÃ§mek iÃ§in, `HandleRequests` sÄ±nÄ±fÄ±ndaki `do_GET` metodunda histogram metriÄŸini ÅŸu ÅŸekilde kullanÄ±lÄ±yor:

```python
@REQUEST_RESPOND_TIME.time()
```

Bu dekoratÃ¶r, `do_GET` metodunun Ã§alÄ±ÅŸma sÃ¼resini Ã¶lÃ§er ve bu sÃ¼reyi `REQUEST_RESPOND_TIME` histogramÄ±na gÃ¶re ilgili kovalara daÄŸÄ±tÄ±r.

SonuÃ§ olarak, bu kod parÃ§acÄ±ÄŸÄ±, bir web sunucusu baÅŸlatÄ±r ve gelen HTTP isteklerine yanÄ±t verir. AynÄ± zamanda, Prometheus iÃ§in bir Histogram metrik tÃ¼rÃ¼ kullanarak yanÄ±t sÃ¼relerini Ã¶lÃ§er ve bu sÃ¼releri belirli kova aralÄ±klarÄ±na gÃ¶re gruplandÄ±rÄ±r. Bu sayede, uygulamanÄ±n yanÄ±t sÃ¼relerini daha iyi anlayabilir ve performansÄ±nÄ± izleyebilirsiniz.

{% hint style="info" %}
`app_response_latency_seconds_bucket{le="+Inf"}` ifadesi, Prometheus tarafÄ±ndan histogram metriÄŸi iÃ§in otomatik olarak oluÅŸturulan Ã¶zel bir kova (bucket) etiketini temsil eder. Bu Ã¶zel kova, belirtilen kova sÄ±nÄ±rlarÄ±nÄ±n Ã¼stÃ¼nde olan tÃ¼m Ã¶lÃ§Ã¼m deÄŸerlerini toplar.

`le` etiketi "less than or equal to" (eÅŸit veya kÃ¼Ã§Ã¼k) anlamÄ±na gelir ve `+Inf` (artÄ± sonsuz) deÄŸeri, bu kovanÄ±n belirtilen tÃ¼m diÄŸer kova sÄ±nÄ±rlarÄ±nÄ±n Ã¼stÃ¼nde olan deÄŸerleri toplayacaÄŸÄ±nÄ± gÃ¶sterir.

Ã–rneÄŸin, histogram metriÄŸi iÃ§in kova sÄ±nÄ±rlarÄ± ÅŸu ÅŸekilde tanÄ±mlanmÄ±ÅŸ olsaydÄ±: `buckets=[0.1,0.5,1,2,3,4,5,10]`, `app_response_latency_seconds_bucket{le="+Inf"}` kovasÄ±, 10 saniyeden fazla sÃ¼ren tÃ¼m yanÄ±t sÃ¼relerini toplayacak.
{% endhint %}

<figure><img src="../.gitbook/assets/image (60).png" alt=""><figcaption></figcaption></figure>

Soru 1 => bÃ¼tÃ¼n bucket deÄŸerleri eÅŸit ilerliyor. TÃ¼m istekler nasÄ±l aynÄ± anda bÃ¼tÃ¼n bucketlara eÅŸit oluyor?

Cevap => Bu durum, Ã¶rnek uygulamanÄ±zdaki tÃ¼m isteklerin 2.0 saniyeden daha kÄ±sa sÃ¼rede tamamlandÄ±ÄŸÄ±nÄ± gÃ¶stermektedir. Histogram metriÄŸinin Ã§alÄ±ÅŸma ÅŸekli nedeniyle, herhangi bir istek sÃ¼resi, o sÃ¼reden daha bÃ¼yÃ¼k veya eÅŸit olan tÃ¼m `le` deÄŸerlerine sahip bucket'lara dahil edilir.

Ã–rneÄŸin, bir isteÄŸin sÃ¼resi 1.5 saniye olsun. Bu durumda, histogram metriÄŸi ÅŸu ÅŸekilde gÃ¼ncellenir:

* 2.0 saniyeden daha kÄ±sa olduÄŸu iÃ§in `app_response_latency_seconds_bucket{le="2.0"}` deÄŸerini artÄ±rÄ±r.
* 5.0 saniyeden daha kÄ±sa olduÄŸu iÃ§in `app_response_latency_seconds_bucket{le="5.0"}` deÄŸerini artÄ±rÄ±r.
* 10.0 saniyeden daha kÄ±sa olduÄŸu iÃ§in `app_response_latency_seconds_bucket{le="10.0"}` deÄŸerini artÄ±rÄ±r.
* Sonsuz saniyeden daha kÄ±sa olduÄŸu iÃ§in `app_response_latency_seconds_bucket{le="+Inf"}` deÄŸerini artÄ±rÄ±r.

EÄŸer tÃ¼m istekler 2.0 saniyeden daha kÄ±sa sÃ¼rede tamamlanÄ±rsa, bu durumda tÃ¼m bu bucket'lar eÅŸit deÄŸerlerle artacaktÄ±r. Bu, gÃ¶zlemlediÄŸiniz durumdur. Ä°stek sÃ¼relerinin daÄŸÄ±lÄ±mÄ±nÄ± daha iyi gÃ¶rmek iÃ§in, uygulamanÄ±zdaki `time.sleep()` fonksiyonuyla rastgele bekleme sÃ¼relerini deÄŸiÅŸtirebilirsiniz. Ã–rneÄŸin, sÃ¼releri 0.1 ile 10 arasÄ±nda rastgele seÃ§erseniz, farklÄ± bucket'larda farklÄ± sayÄ±lar gÃ¶rmeye baÅŸlarsÄ±nÄ±z.



